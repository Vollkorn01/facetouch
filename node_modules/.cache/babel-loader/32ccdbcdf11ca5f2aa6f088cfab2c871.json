{"remainingRequest":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/babel-loader/lib/index.js!/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js??ref--0-0!/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue?vue&type=script&lang=js&","dependencies":[{"path":"/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue","mtime":1584299323911},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/babel-loader/lib/index.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64: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"},{"version":3,"sources":["FaceTouch.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkDA;AAEA,eAAA;AACA,EAAA,IAAA,EAAA,WADA;AAEA,EAAA,UAAA,EAAA,EAFA;AAGA,EAAA,IAAA,EAAA,gBAAA;AACA,WAAA;AACA,MAAA,KAAA,EAAA;AADA,KAAA;AAGA,GAPA;AAQA,EAAA,OAAA,EAAA,mBAAA,CACA;AACA,GAVA;AAYA,EAAA,OAAA,EAAA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AADA;AAZA,CAAA","sourcesContent":["<template>\n  <div class=\"container\">\n    <!--\n    <div>\n      <h1 class=\"title\">\n        VIDEO\n      </h1>\n\n      <canvas\n        id=\"canvas\"\n        class=\"border\"\n      />\n\n    </div>\n\n    <div class=\"p20\">\n      Handtrack.js allows you prototype handtracking interactions in the browser\n      in 10 lines of code.\n    </div>\n    <div class=\"mb10\">\n      <button\n        id=\"trackbutton\"\n        class=\"bx--btn bx--btn--secondary\"\n        type=\"button\"\n        @click=\"toggleVideo()\"\n      >\n        Toggle Video\n      </button>\n      <div\n        id=\"updatenote\"\n        class=\"updatenote mt10\"\n      >\n        loading model ..\n      </div>\n    </div>\n    <video\n      id=\"myvideo\"\n      class=\"videobox canvasbox\"\n      autoplay=\"autoplay\"\n    />\n\n    <canvas\n      id=\"canvas\"\n      class=\"border canvasbox\"\n    />\n     -->\n  </div>\n</template>\n\n<script>\n//import * as handTrack from 'handtrackjs'\n\nexport default {\n  name: 'FaceTouch',\n  components: {},\n  data: function() {\n    return {\n      model: null\n    }\n  },\n  mounted: function() {\n    //this.startHandTrack()\n  },\n\n  methods: {\n    /*\n    startHandTrack() {\n      let trackButton = document.getElementById('trackbutton')\n      //let updateNote = document.getElementById('updatenote')\n\n      const modelParams = {\n        flipHorizontal: true, // flip e.g for video\n        maxNumBoxes: 20, // maximum number of boxes to detect\n        iouThreshold: 0.5, // ioU threshold for non-max suppression\n        scoreThreshold: 0.6 // confidence threshold for predictions.\n      }\n\n      // Load the model.\n      handTrack.load(modelParams).then((lmodel) => {\n        // detect objects in the image.\n        this.model = lmodel\n        console.log('model: ', this.model)\n        //updateNote.innerText = 'Loaded Model!'\n        trackButton.disabled = false\n      })\n      console.log('model: ', this.model)\n    },\n\n    startVideo(video, isVideo, canvas, context, model) {\n      // eslint-disable-next-line no-undef\n      handTrack.startVideo(video).then((status) => {\n        console.log('video started', status)\n        if (status) {\n          //updateNote.innerText = 'Video started. Now tracking'\n          isVideo = true\n          this.runDetection(video, isVideo, canvas, context, model)\n        } else {\n          //updateNote.innerText = 'Please enable video'\n        }\n      })\n    },\n\n    toggleVideo() {\n      const video = document.getElementById('myvideo')\n      const canvas = document.getElementById('canvas')\n      const context = canvas.getContext('2d')\n      //let updateNote = document.getElementById('updatenote')\n\n      let isVideo = false\n\n      if (!isVideo) {\n        //updateNote.innerText = 'Starting video'\n        this.startVideo(video, isVideo, canvas, context)\n      } else {\n        //updateNote.innerText = 'Stopping video'\n        this.handTrack.stopVideo(video)\n        isVideo = false\n        //updateNote.innerText = 'Video stopped'\n      }\n    },\n\n    runDetection(video, isVideo, canvas, context) {\n      this.model.detect(video).then((predictions) => {\n        console.log('Predictions: ', predictions)\n        this.model.renderPredictions(predictions, canvas, context, video)\n        if (isVideo) {\n          requestAnimationFrame(this.runDetection)\n        }\n      })\n    }\n    */\n  }\n}\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n.container {\n  margin: 0 auto;\n  min-height: 100vh;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  text-align: center;\n}\n\n.title {\n  font-family: 'Quicksand', 'Source Sans Pro', -apple-system, BlinkMacSystemFont,\n    'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n  display: block;\n  font-weight: 300;\n  font-size: 100px;\n  color: #35495e;\n  letter-spacing: 1px;\n}\n\n.subtitle {\n  font-weight: 300;\n  font-size: 42px;\n  color: #526488;\n  word-spacing: 5px;\n  padding-bottom: 15px;\n}\n\n.links {\n  padding-top: 15px;\n}\nbody {\n  padding: 20px;\n}\n\n.p20 {\n  padding: 20px;\n}\n\n.canvasbox {\n  border-radius: 3px;\n  margin-right: 10px;\n  width: 450px;\n  height: 338px;\n  border-bottom: 3px solid #0063ff;\n  box-shadow: 0 2px 3px 0 rgba(0, 0, 0, 0.2), 0 4px 10px 0 #00000030;\n  background: #333;\n}\n\n.mb10 {\n  margin-bottom: 10px;\n}\n\n.mt10 {\n  margin-top: 10px;\n}\n\n.updatenote {\n  padding: 10px;\n  background: rgb(245, 147, 20);\n  color: white;\n  display: inline;\n}\n</style>\n"],"sourceRoot":"src/components"}]}