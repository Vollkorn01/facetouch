{"remainingRequest":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue?vue&type=style&index=0&id=494b41e2&scoped=true&lang=css&","dependencies":[{"path":"/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue","mtime":1584302425851},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/css-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/loaders/stylePostLoader.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/postcss-loader/src/index.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64:CgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKLmNvbnRhaW5lciB7CiAgbWFyZ2luOiAwIGF1dG87CiAgbWluLWhlaWdodDogMTAwdmg7CiAgZGlzcGxheTogZmxleDsKICBqdXN0aWZ5LWNvbnRlbnQ6IGNlbnRlcjsKICBhbGlnbi1pdGVtczogY2VudGVyOwogIHRleHQtYWxpZ246IGNlbnRlcjsKfQoKLnRpdGxlIHsKICBmb250LWZhbWlseTogJ1F1aWNrc2FuZCcsICdTb3VyY2UgU2FucyBQcm8nLCAtYXBwbGUtc3lzdGVtLCBCbGlua01hY1N5c3RlbUZvbnQsCiAgICAnU2Vnb2UgVUknLCBSb2JvdG8sICdIZWx2ZXRpY2EgTmV1ZScsIEFyaWFsLCBzYW5zLXNlcmlmOwogIGRpc3BsYXk6IGJsb2NrOwogIGZvbnQtd2VpZ2h0OiAzMDA7CiAgZm9udC1zaXplOiAxMDBweDsKICBjb2xvcjogIzM1NDk1ZTsKICBsZXR0ZXItc3BhY2luZzogMXB4Owp9Cgouc3VidGl0bGUgewogIGZvbnQtd2VpZ2h0OiAzMDA7CiAgZm9udC1zaXplOiA0MnB4OwogIGNvbG9yOiAjNTI2NDg4OwogIHdvcmQtc3BhY2luZzogNXB4OwogIHBhZGRpbmctYm90dG9tOiAxNXB4Owp9CgoubGlua3MgewogIHBhZGRpbmctdG9wOiAxNXB4Owp9CmJvZHkgewogIHBhZGRpbmc6IDIwcHg7Cn0KCi5wMjAgewogIHBhZGRpbmc6IDIwcHg7Cn0KCi5jYW52YXNib3ggewogIGJvcmRlci1yYWRpdXM6IDNweDsKICBtYXJnaW4tcmlnaHQ6IDEwcHg7CiAgd2lkdGg6IDQ1MHB4OwogIGhlaWdodDogMzM4cHg7CiAgYm9yZGVyLWJvdHRvbTogM3B4IHNvbGlkICMwMDYzZmY7CiAgYm94LXNoYWRvdzogMCAycHggM3B4IDAgcmdiYSgwLCAwLCAwLCAwLjIpLCAwIDRweCAxMHB4IDAgIzAwMDAwMDMwOwogIGJhY2tncm91bmQ6ICMzMzM7Cn0KCi5tYjEwIHsKICBtYXJnaW4tYm90dG9tOiAxMHB4Owp9CgoubXQxMCB7CiAgbWFyZ2luLXRvcDogMTBweDsKfQoKLnVwZGF0ZW5vdGUgewogIHBhZGRpbmc6IDEwcHg7CiAgYmFja2dyb3VuZDogcmdiKDI0NSwgMTQ3LCAyMCk7CiAgY29sb3I6IHdoaXRlOwogIGRpc3BsYXk6IGlubGluZTsKfQo="},{"version":3,"sources":["FaceTouch.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA","file":"FaceTouch.vue","sourceRoot":"src/components","sourcesContent":["<template>\n  <div class=\"container\">\n    <div>\n      <h1 class=\"title\">\n        VIDEO\n      </h1>\n\n      <canvas\n        id=\"canvas\"\n        class=\"border\"\n      />\n    </div>\n\n    <div class=\"p20\">\n      Handtrack.js allows you prototype handtracking interactions in the browser\n      in 10 lines of code.\n    </div>\n    <div class=\"mb10\">\n      <button\n        id=\"trackbutton\"\n        class=\"bx--btn bx--btn--secondary\"\n        type=\"button\"\n        @click=\"toggleVideo()\"\n      >\n        Toggle Video\n      </button>\n      <div\n        id=\"updatenote\"\n        class=\"updatenote mt10\"\n      >\n        loading model ..\n      </div>\n    </div>\n    <video\n      id=\"myvideo\"\n      class=\"videobox canvasbox\"\n      autoplay=\"autoplay\"\n    />\n\n    <canvas\n      id=\"canvas\"\n      class=\"border canvasbox\"\n    />\n    <script type=\"module\">\n      import * as handTrack from 'https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js'\n    </script>\n  </div>\n</template>\n\n<script>\n//import * as handTrack from 'handtrackjs'\n\nexport default {\n  name: 'FaceTouch',\n  components: {},\n  data: function() {\n    return {\n      model: null\n    }\n  },\n  mounted: function() {\n    this.startHandTrack()\n  },\n\n  methods: {\n    startHandTrack() {\n      let trackButton = document.getElementById('trackbutton')\n      //let updateNote = document.getElementById('updatenote')\n\n      const modelParams = {\n        flipHorizontal: true, // flip e.g for video\n        maxNumBoxes: 20, // maximum number of boxes to detect\n        iouThreshold: 0.5, // ioU threshold for non-max suppression\n        scoreThreshold: 0.6 // confidence threshold for predictions.\n      }\n\n      // Load the model.\n      // eslint-disable-next-line no-undef\n      handTrack.load(modelParams).then((lmodel) => {\n        // detect objects in the image.\n        this.model = lmodel\n        console.log('model: ', this.model)\n        //updateNote.innerText = 'Loaded Model!'\n        trackButton.disabled = false\n      })\n      console.log('model: ', this.model)\n    },\n\n    startVideo(video, isVideo, canvas, context, model) {\n      // eslint-disable-next-line no-undef\n      handTrack.startVideo(video).then((status) => {\n        console.log('video started', status)\n        if (status) {\n          //updateNote.innerText = 'Video started. Now tracking'\n          isVideo = true\n          this.runDetection(video, isVideo, canvas, context, model)\n        } else {\n          //updateNote.innerText = 'Please enable video'\n        }\n      })\n    },\n\n    toggleVideo() {\n      const video = document.getElementById('myvideo')\n      const canvas = document.getElementById('canvas')\n      const context = canvas.getContext('2d')\n      //let updateNote = document.getElementById('updatenote')\n\n      let isVideo = false\n\n      if (!isVideo) {\n        //updateNote.innerText = 'Starting video'\n        this.startVideo(video, isVideo, canvas, context)\n      } else {\n        //updateNote.innerText = 'Stopping video'\n        this.handTrack.stopVideo(video)\n        isVideo = false\n        //updateNote.innerText = 'Video stopped'\n      }\n    },\n\n    runDetection(video, isVideo, canvas, context) {\n        console.log('running detection on video: ', video, 'and context: ', context)\n      this.model.detect(video).then((predictions) => {\n        console.log('Predictions: ', predictions)\n        this.model.renderPredictions(predictions, canvas, context, video)\n        if (isVideo) {\n          requestAnimationFrame(this.runDetection)\n        }\n      })\n    }\n    \n  }\n}\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n.container {\n  margin: 0 auto;\n  min-height: 100vh;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  text-align: center;\n}\n\n.title {\n  font-family: 'Quicksand', 'Source Sans Pro', -apple-system, BlinkMacSystemFont,\n    'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n  display: block;\n  font-weight: 300;\n  font-size: 100px;\n  color: #35495e;\n  letter-spacing: 1px;\n}\n\n.subtitle {\n  font-weight: 300;\n  font-size: 42px;\n  color: #526488;\n  word-spacing: 5px;\n  padding-bottom: 15px;\n}\n\n.links {\n  padding-top: 15px;\n}\nbody {\n  padding: 20px;\n}\n\n.p20 {\n  padding: 20px;\n}\n\n.canvasbox {\n  border-radius: 3px;\n  margin-right: 10px;\n  width: 450px;\n  height: 338px;\n  border-bottom: 3px solid #0063ff;\n  box-shadow: 0 2px 3px 0 rgba(0, 0, 0, 0.2), 0 4px 10px 0 #00000030;\n  background: #333;\n}\n\n.mb10 {\n  margin-bottom: 10px;\n}\n\n.mt10 {\n  margin-top: 10px;\n}\n\n.updatenote {\n  padding: 10px;\n  background: rgb(245, 147, 20);\n  color: white;\n  display: inline;\n}\n</style>\n"]}]}