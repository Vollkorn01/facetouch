{"remainingRequest":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue?vue&type=script&lang=js&","dependencies":[{"path":"/Users/alexander/Documents/DevProjects/facetouch/src/components/FaceTouch.vue","mtime":1584302425851},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/babel-loader/lib/index.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/alexander/Documents/DevProjects/facetouch/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64: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"},{"version":3,"sources":["FaceTouch.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkDA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA","file":"FaceTouch.vue","sourceRoot":"src/components","sourcesContent":["<template>\n  <div class=\"container\">\n    <div>\n      <h1 class=\"title\">\n        VIDEO\n      </h1>\n\n      <canvas\n        id=\"canvas\"\n        class=\"border\"\n      />\n    </div>\n\n    <div class=\"p20\">\n      Handtrack.js allows you prototype handtracking interactions in the browser\n      in 10 lines of code.\n    </div>\n    <div class=\"mb10\">\n      <button\n        id=\"trackbutton\"\n        class=\"bx--btn bx--btn--secondary\"\n        type=\"button\"\n        @click=\"toggleVideo()\"\n      >\n        Toggle Video\n      </button>\n      <div\n        id=\"updatenote\"\n        class=\"updatenote mt10\"\n      >\n        loading model ..\n      </div>\n    </div>\n    <video\n      id=\"myvideo\"\n      class=\"videobox canvasbox\"\n      autoplay=\"autoplay\"\n    />\n\n    <canvas\n      id=\"canvas\"\n      class=\"border canvasbox\"\n    />\n    <script type=\"module\">\n      import * as handTrack from 'https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js'\n    </script>\n  </div>\n</template>\n\n<script>\n//import * as handTrack from 'handtrackjs'\n\nexport default {\n  name: 'FaceTouch',\n  components: {},\n  data: function() {\n    return {\n      model: null\n    }\n  },\n  mounted: function() {\n    this.startHandTrack()\n  },\n\n  methods: {\n    startHandTrack() {\n      let trackButton = document.getElementById('trackbutton')\n      //let updateNote = document.getElementById('updatenote')\n\n      const modelParams = {\n        flipHorizontal: true, // flip e.g for video\n        maxNumBoxes: 20, // maximum number of boxes to detect\n        iouThreshold: 0.5, // ioU threshold for non-max suppression\n        scoreThreshold: 0.6 // confidence threshold for predictions.\n      }\n\n      // Load the model.\n      // eslint-disable-next-line no-undef\n      handTrack.load(modelParams).then((lmodel) => {\n        // detect objects in the image.\n        this.model = lmodel\n        console.log('model: ', this.model)\n        //updateNote.innerText = 'Loaded Model!'\n        trackButton.disabled = false\n      })\n      console.log('model: ', this.model)\n    },\n\n    startVideo(video, isVideo, canvas, context, model) {\n      // eslint-disable-next-line no-undef\n      handTrack.startVideo(video).then((status) => {\n        console.log('video started', status)\n        if (status) {\n          //updateNote.innerText = 'Video started. Now tracking'\n          isVideo = true\n          this.runDetection(video, isVideo, canvas, context, model)\n        } else {\n          //updateNote.innerText = 'Please enable video'\n        }\n      })\n    },\n\n    toggleVideo() {\n      const video = document.getElementById('myvideo')\n      const canvas = document.getElementById('canvas')\n      const context = canvas.getContext('2d')\n      //let updateNote = document.getElementById('updatenote')\n\n      let isVideo = false\n\n      if (!isVideo) {\n        //updateNote.innerText = 'Starting video'\n        this.startVideo(video, isVideo, canvas, context)\n      } else {\n        //updateNote.innerText = 'Stopping video'\n        this.handTrack.stopVideo(video)\n        isVideo = false\n        //updateNote.innerText = 'Video stopped'\n      }\n    },\n\n    runDetection(video, isVideo, canvas, context) {\n        console.log('running detection on video: ', video, 'and context: ', context)\n      this.model.detect(video).then((predictions) => {\n        console.log('Predictions: ', predictions)\n        this.model.renderPredictions(predictions, canvas, context, video)\n        if (isVideo) {\n          requestAnimationFrame(this.runDetection)\n        }\n      })\n    }\n    \n  }\n}\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n.container {\n  margin: 0 auto;\n  min-height: 100vh;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  text-align: center;\n}\n\n.title {\n  font-family: 'Quicksand', 'Source Sans Pro', -apple-system, BlinkMacSystemFont,\n    'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n  display: block;\n  font-weight: 300;\n  font-size: 100px;\n  color: #35495e;\n  letter-spacing: 1px;\n}\n\n.subtitle {\n  font-weight: 300;\n  font-size: 42px;\n  color: #526488;\n  word-spacing: 5px;\n  padding-bottom: 15px;\n}\n\n.links {\n  padding-top: 15px;\n}\nbody {\n  padding: 20px;\n}\n\n.p20 {\n  padding: 20px;\n}\n\n.canvasbox {\n  border-radius: 3px;\n  margin-right: 10px;\n  width: 450px;\n  height: 338px;\n  border-bottom: 3px solid #0063ff;\n  box-shadow: 0 2px 3px 0 rgba(0, 0, 0, 0.2), 0 4px 10px 0 #00000030;\n  background: #333;\n}\n\n.mb10 {\n  margin-bottom: 10px;\n}\n\n.mt10 {\n  margin-top: 10px;\n}\n\n.updatenote {\n  padding: 10px;\n  background: rgb(245, 147, 20);\n  color: white;\n  display: inline;\n}\n</style>\n"]}]}